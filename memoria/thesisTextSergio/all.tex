
\chapter{Triton Implementation of the TVC Kernel}
\section{Porting Strategy from CPU dTVC to Triton}
\section{Triton Kernel Architecture}
\section{Memory Management and Tiling Strategies}
\section{Handling High-Dimensionality in Triton}
\section{Integration into the existing dTVC Framework}

\chapter{Low-Level Optimization with CUDA}
\section{Rationale for a Native CUDA Implementation}
\section{Parallelization Strategy and Thread Mapping}
\section{Memory Hierarchy Exploitation}
\subsection{Coalesced Global Memory Access}
\subsection{Shared Memory and Register Optimization}
\section{Acceleration of the HOPM algorithm}

\chapter{Experimental Setup and Methodology}
\section{Computing Resources: BSC Cluster Infrastructure}
\section{Dataset Selection and Workload Generation}
\section{Performance Metrics}
\subsection{Execution Time and Speedup}
\subsection{Throughput and Effective Memory Bandwidth}
\section{Validation and Correctness Checking}

\chapter{Evaluation and Results}
\section{Triton Implementation vs. CPU State-of-the-Art}
\section{Performance Comparison: Triton vs. Native CUDA}
\section{HOPM Convergence Analysis on GPUs}
\section{Scalability and Bottleneck Identification}

\chapter{Conclusions and Future Work}
\section{Project Synthesis}
\section{Key Findings: Development Effort vs. Peak Performance}
\section{Future Lines of Research}


\chapter*{References}
\addcontentsline{toc}{chapter}{References}

% --- Appendices ---
\begin{appendices}
\chapter{Triton TVC Kernel Snippets}
\chapter{CUDA TVC Kernel Snippets}
\chapter{List of Abbreviations}
\end{appendices}
